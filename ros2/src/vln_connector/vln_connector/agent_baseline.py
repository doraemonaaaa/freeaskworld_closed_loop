import os
import cv2
import time
import json
import rclpy
import numpy as np
import math
import re
import numpy as np
from pathlib import Path
from dotenv import load_dotenv
import tempfile
import threading

# å¼•å…¥ AgentFlow ä¾èµ–
from agentflow.agentflow.solver_embodied import construct_solver_embodied

# å¼•å…¥ ROS æ¶ˆæ¯
from simulator_messages.msg import NavigationCommand  # è‡ªå®šä¹‰æ¶ˆæ¯
from .rgbd_connector import VLNConnector


class AgentBaseline(VLNConnector):
    """
    ä¸²è¡Œ LLM æ§åˆ¶ Agentï¼ˆæ—  ROS Timerï¼‰
    æ¯ä¸€è½®ï¼š
        ROS spin -> InputData -> Inference -> Publish
    """

    def __init__(self):
        super().__init__()  # åˆå§‹åŒ– ROS Node + RGBD Subscriber

        # ä¸´æ—¶ç›®å½•
        self._temp_dir = tempfile.TemporaryDirectory()
        self.get_logger().info(f"Temporary directory created: {self._temp_dir.name}")
        self._lock = threading.Lock()  # æ¨ç†é”
        self._inference_thread = None

        # -------------------------------------------------
        # 1. ç¯å¢ƒ & LLM é…ç½®
        # -------------------------------------------------
        load_dotenv(dotenv_path="agentflow/.env")
        self.get_logger().info(
            f"OpenAI Key Loaded: {'OPENAI_API_KEY' in os.environ}"
        )

        self.llm_engine_name = "gpt-4o"

        self.solver = construct_solver_embodied(
            llm_engine_name=self.llm_engine_name,
            enabled_tools=[
                "Base_Generator_Tool",
                "GroundedSAM2_Tool"
            ],
            tool_engine=["gpt-4o"],
            model_engine=["gpt-4o", "gpt-4o", "gpt-4o"],
            output_types="direct",
            max_time=300,
            max_steps=1,
            enable_multimodal=True
        )

        # -------------------------------------------------
        # 2. Agent çŠ¶æ€
        # -------------------------------------------------
        self.task_prompt = (
            "Go to the <æˆ‘å’Œä¹”æ²»å•†åº—>, task finish upon arrival within 2 meters."
        )

        self.temp_dir = Path("tmp/agent_baseline")
        self.temp_dir.mkdir(parents=True, exist_ok=True)

        self.step_counter = 0
        self.last_infer_step = -1  # é˜²æ­¢åŒä¸€å¸§é‡å¤æ¨ç†

        self.get_logger().info("AgentBaseline Initialized")

        self._stop_event = threading.Event()

    # =====================================================
    # ä¸»æ§åˆ¶é€»è¾‘ï¼ˆå•æ­¥ï¼‰
    # =====================================================
    def control_once_async(self):
        # å¦‚æœä¸Šä¸€è½®æ¨ç†è¿˜åœ¨æ‰§è¡Œï¼Œä¸å¯åŠ¨æ–°æ¨ç†
        if self._inference_thread is not None and self._inference_thread.is_alive():
            return

        # snapshot æœ€æ–° RGB/D
        rgb_snapshot = self.rgb_image.copy() if self.rgb_image is not None else None
        depth_snapshot = self.depth_image.copy() if self.depth_image is not None else None

        if rgb_snapshot is None:
            return

        # éé˜»å¡è°ƒç”¨ Inference
        self._inference_thread = threading.Thread(
            target=self.Inference, kwargs={"rgb": rgb_snapshot, "depth": depth_snapshot}
        )
        self._inference_thread.start()

    # =====================================================
    # Input Adapter
    # =====================================================
    def InputData(self, **kwargs):
        """
        å°† ROS å†…å­˜å›¾åƒä¿å­˜ä¸ºæ–‡ä»¶ï¼Œä¾› AgentFlow ä½¿ç”¨
        """
        rgb_img = kwargs.get("rgb")

        file_name = f"step_{self.step_counter:04d}.jpg"
        file_path = self.temp_dir / file_name

        cv2.imwrite(str(file_path), rgb_img)
        self.step_counter += 1

        return [str(file_path)]

    # =====================================================
    # Inference Adapter
    # =====================================================
    def Inference(self, **args):
        """
        é€šç”¨ LLM æ¨ç†æ¥å£ï¼ˆå¯æ¥æ”¶ä»»æ„è¾“å…¥ via **argsï¼‰
        çº¿ç¨‹å®‰å…¨ï¼Œè¿”å› NavigationCommand
        """
        image_paths = args.get("image_paths", None)
        if image_paths is None:
            rgb = args.get("rgb")
            depth = args.get("depth")  # depth å¯ä»¥ç•™ç€ä»¥åç”¨
            if rgb is None:
                self.get_logger().warn("No RGB input for inference, skipping")
                return None
            image_paths = self.InputData(rgb=rgb, depth=depth)

        self.get_logger().info(f"[LLM] Thinking... input={image_paths[-1]}")

        try:
            output = self.solver.solve(
                self.task_prompt,
                image_paths=image_paths
            )

            raw_text = output.get("direct_output", "")
            nav_cmd = self._parse_llm_to_ros(raw_text)

            if nav_cmd is not None:
                self.publish_navigation_command(nav_cmd)

            if nav_cmd.is_stop:
                self.get_logger().info("ğŸ Stop received, exiting baseline for restart")
                self._stop_event.set()
                
            return nav_cmd
        
        except Exception as e:
            self.get_logger().error(f"Inference Error: {e}")
            return None
        
    def destroy_node(self):
        super().destroy_node()
        self._temp_dir.cleanup()
        self.get_logger().info("Temporary directory cleaned up.")

    def _parse_llm_to_ros(self, output_text: str):
        cmd = NavigationCommand()
        cmd.header.stamp = self.get_clock().now().to_msg()
        cmd.header.frame_id = "agent"
        
        # Unity: Z=Forward, X=Right, Y=Up
        pos_offset = [0.0, 0.0, 0.0] 
        rot_offset = [0.0, 0.0, 0.0, 1.0] # Identity quaternion (x, y, z, w)
        is_stopped = False

        # 1. æå– Action åçš„å†…å®¹
        # åŒ¹é… **Action**: æˆ– Action: æˆ– Navigation Goal:
        action_match = re.search(
            r"(?:\*\*Action\*\*|Action|Navigation Goal)\s*:\s*(.*)",
            output_text,
            re.IGNORECASE | re.DOTALL
        )

        if action_match:
            # è·å–æ ‡ç­¾åçš„æ‰€æœ‰æ–‡æœ¬å¹¶å»é™¤ç©ºç™½
            action_text = action_match.group(1).strip()
            self.get_logger().info(f"Extracted Action Text: {action_text}")

            # --- Case 1: <Move(x, y, yaw)> ---
            # æ³¨æ„ï¼šè¿™é‡Œæ­£åˆ™åŒ¹é… float, æ•è· x, y, yaw
            move_match = re.search(
                r"<Move\(\s*(-?\d+\.?\d*)\s*,\s*(-?\d+\.?\d*)\s*,\s*(-?\d+\.?\d*)\s*\)>", 
                action_text, 
                re.IGNORECASE
            )
            if move_match:
                x = float(move_match.group(1))     # Agent Forward
                y = float(move_match.group(2))     # Agent Right
                yaw_deg = float(move_match.group(3)) # Rotation in degrees
                
                self.get_logger().info(f"Parsed Move: x={x}, y={y}, yaw={yaw_deg}")

                # åæ ‡ç³»æ˜ å°„é€»è¾‘:
                # Agent X (Forward) -> Sim Z (Unity Forward)
                # Agent Y (Right)   -> Sim X (Unity Right)
                pos_offset[2] = x  # Z
                pos_offset[0] = y  # X
                pos_offset[1] = 0.0 # Y (Up)
                
                # æ—‹è½¬æ˜ å°„ (ç»• Y è½´)
                yaw_rad = np.radians(yaw_deg)
                half_angle = yaw_rad / 2.0
                rot_offset[1] = np.sin(half_angle) # Y
                rot_offset[3] = np.cos(half_angle) # W

            # --- Case 2: <Rotate(yaw)> ---
            rotate_match = re.search(
                r"<Rotate\(\s*(-?\d+\.?\d*)\s*\)>", 
                action_text, 
                re.IGNORECASE
            )
            if rotate_match:
                yaw_deg = float(rotate_match.group(1))
                self.get_logger().info(f"Parsed Rotate: yaw={yaw_deg}")
                yaw_rad = np.radians(yaw_deg)
                half_angle = yaw_rad / 2.0
                rot_offset[1] = np.sin(half_angle)
                rot_offset[3] = np.cos(half_angle)

            # --- Case 3: <Stop> ---
            if "<Stop>" in action_text or "Stop()" in action_text:
                is_stopped = True
                self.get_logger().info("Action: STOP")

        else:
            # å¦‚æœæ ¹æœ¬æ²¡æ‰¾åˆ° Action: æ ‡ç­¾
            self.get_logger().warn("Label 'Action:' not found in LLM output. Stopping for safety.")
            is_stopped = True

        # å¡«å…… ROS æ¶ˆæ¯å­—æ®µ
        cmd.local_position_offset = pos_offset
        cmd.local_rotation_offset = rot_offset
        cmd.is_stop = is_stopped

        return cmd


# =====================================================
# Main Loopï¼ˆæ—  Timerï¼Œä¸²è¡Œï¼‰
# =====================================================
def main(args=None):
    rclpy.init(args=args)
    node = AgentBaseline()

    try:
        while rclpy.ok():
            rclpy.spin_once(node, timeout_sec=0.05)  # æŒç»­åˆ·æ–°è®¢é˜…æ•°æ®
            node.control_once_async()               # éé˜»å¡æ¨ç†

            if node._stop_event.is_set():
                node.get_logger().info("ğŸ” Baseline reseting...")
                break
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()
